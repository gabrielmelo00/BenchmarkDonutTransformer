{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eB4nGDts2_xB",
        "outputId": "c96ff4f8-4742-41ea-8f04-6e6c30aa96ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN2CBqcD3HNC",
        "outputId": "05cc6efa-c9e5-463e-fa95-ae14b4fbd2dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q datasets sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpNIa_rH399o"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq0_wSlubCQq"
      },
      "source": [
        "Load the dataset created by Niels Rogge [here](https://github.com/NielsRogge/Transformers-Tutorials/blob/master/Donut/RVL-CDIP/Preparing_an_image_classification_dataset_for_Donut.ipynb). This is a small subset of the entire  RVL-CDIP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304,
          "referenced_widgets": [
            "911bfe78a5394368afc5090a53cb5c40",
            "bf95360d5ec94c45a1c082843f584e9d",
            "4a7bb0de87994c1991fa7bdd6a7eca75",
            "7ad10c45ba07441a8d45deee496bbd8e",
            "6e1bd8d09e3845eea723f38972d47c17",
            "c3faf25f31e04049b560efbb69436548",
            "289189cc98854d61a0740660b1e5429d",
            "6061bf09d95141b6a458fdda8a048e9b",
            "02d827458878407bb7c5213c33be8787",
            "e9502aeee17d4a5c9e987814f5f59ad6",
            "763b4bf300874fe08ce777dda65d2302",
            "dae45f65797247afb676b9b5e7230bd9",
            "0cc4a304282e440fabd16f1adc7dc940",
            "2115d10e11b24c2da01ff92ead03ba54",
            "d9769fee088547b49061389d952dc427",
            "48fc02947ba0419096c249d66d8b2bc7",
            "dfa98b17bbce46f38782843d57d57dc8",
            "4ea36b95098d444fa614cc5ba9040da4",
            "4ab6a96b5f474fb69da4cc45da19c797",
            "3297c236f5a449578cec129274934bcd",
            "abb613745c5c49b18cb38838331e08fa",
            "f2f3c724b7d94770a0e2958d38c55209",
            "e1ee114025fb4eb88fe1ed3c568ce5dc",
            "6a8be9f4b12a43369110348e195dcf09",
            "0428f83a3ac44de4a0f2f7100c215c7e",
            "0af81bb0953347e7a3914ef17972ead7",
            "1961386562c44d058cfc8c57d9c98972",
            "32a9f44ba72347159ba89d1cb5e52280",
            "cf32e35d7a7449c48e9a1be78a8ccf67",
            "55fc25da934444d78079295389edc918",
            "6a313774e4074526b713262a47d96036",
            "8d9191b458c945e0841e91edf1caa953",
            "a8e5fa932183439eb48824648d012cba",
            "420e3a55ffae41b89590d1b404dcc866",
            "c8888102c4f34357a9be9a866af506e8",
            "ec3418b4425e47bbaf25d8415ed9c75f",
            "ccf1ca73828a4d1abd3f2cdfd2e280a6",
            "2d00bf9958b74ef1bf167a8504633f66",
            "d37d5f2a006c4b21969cd553b0fca739",
            "6b52514334de4cf08545aa89309c1d01",
            "ec99bfc5d2d24626b751e7dba5025ad6",
            "76056b8c4d524f3d9c919c09bcda859f",
            "8e74c645ccd44fb7a55f9f05d100ca3f",
            "fa017f814c9b4c4cb0511418a8789c16",
            "396df14a13944f20ab868ec65e846b62",
            "4f30e5720e9c4f2e8d27b92a7de52caa",
            "9de5df2c908b4951bf4280b319f66f31",
            "00b3f2ee7cb64e6d987500001503925b",
            "d81702076a8643d1b1ccc365cb487165",
            "5d5f516d34404b24854a633166394b38",
            "c1d36708726a48ddbadd66c144408975",
            "08474e5ba9984b09b0834e013c7fab7f",
            "d3384f079cfc41c19345b23557647b2d",
            "9a37d69db08c4521b010bd5f4932e1f4",
            "6eb543402f9e4f5f9792f9b21860d633"
          ]
        },
        "id": "CYIEs8D63It4",
        "outputId": "81245a64-b57c-4e42-d2cf-ac537fa39c4d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "911bfe78a5394368afc5090a53cb5c40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/1.85k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dae45f65797247afb676b9b5e7230bd9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/18.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1ee114025fb4eb88fe1ed3c568ce5dc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/16.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "420e3a55ffae41b89590d1b404dcc866",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/160 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "396df14a13944f20ab868ec65e846b62",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/160 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"nielsr/rvl_cdip_10_examples_per_class_donut\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chVe2Olj4HjY",
        "outputId": "365bef97-ef36-47fc-e047-396e28f44c5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'letter', 1: 'form', 2: 'email', 3: 'handwritten', 4: 'advertisement', 5: 'scientific report', 6: 'scientific publication', 7: 'specification', 8: 'file folder', 9: 'news article', 10: 'budget', 11: 'invoice', 12: 'presentation', 13: 'questionnaire', 14: 'resume', 15: 'memo'}\n"
          ]
        }
      ],
      "source": [
        "id2label = {id: label for id, label in enumerate(dataset['train'].features['label'].names)}\n",
        "print(id2label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oHk6jRx4UNC"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MPdDnhpb3Lr"
      },
      "source": [
        "Here is the most important part, we created the model for the encoder only donut with classification head in the end. Basically, the encoder will work as feature extraction step. Its pooled output will pass through a dropout and a classifier layer, which maps from number of features to number of classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_-DALg8G4SY4"
      },
      "outputs": [],
      "source": [
        "from transformers import DonutSwinModel, DonutSwinPreTrainedModel\n",
        "from torch import nn\n",
        "import torch\n",
        "\n",
        "class DonutForImageClassification(DonutSwinPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "        self.swin = DonutSwinModel(config)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.classifier = nn.Linear(self.swin.num_features, config.num_labels)\n",
        "\n",
        "    def forward(self, pixel_values: torch.Tensor) -> torch.Tensor:\n",
        "        outputs = self.swin(pixel_values)\n",
        "        pooled_output = outputs[1]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "bR8PpM_W4dp1"
      },
      "outputs": [],
      "source": [
        "from transformers import VisionEncoderDecoderConfig, DonutProcessor, VisionEncoderDecoderModel\n",
        "image_size = [1280, 960]\n",
        "config = VisionEncoderDecoderConfig.from_pretrained(\"nielsr/donut-base\")\n",
        "config.encoder.image_size = image_size\n",
        "\n",
        "processor = DonutProcessor.from_pretrained(\"nielsr/donut-base\")\n",
        "donut_model = VisionEncoderDecoderModel.from_pretrained(\"nielsr/donut-base\", config=config)\n",
        "\n",
        "processor.feature_extractor.size = image_size[::-1] # should be (width, height)\n",
        "processor.feature_extractor.do_align_long_axis = False\n",
        "\n",
        "donut_model.encoder.save_pretrained(\"donut_encoder\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdcK-n7p5pPe",
        "outputId": "cfe84eb2-3ac4-42c5-a5c8-560187789d7d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DonutForImageClassification were not initialized from the model checkpoint at donut_encoder and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = DonutForImageClassification.from_pretrained(\"donut_encoder\", num_labels=16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6_4WethcgRp"
      },
      "source": [
        "Now we can prepare the dataset to be loaded using PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_DBd-wd24tm0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class DocumentDataset(Dataset):\n",
        "    def __init__(self, dataset_name_or_path, split):\n",
        "        self.split = split\n",
        "        self.dataset = load_dataset(dataset_name_or_path, split=self.split)\n",
        "        print(self.dataset)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.dataset[idx]\n",
        "\n",
        "        pixel_values = processor(sample[\"image\"].convert(\"RGB\"), random_padding=self.split == \"train\", return_tensors=\"pt\").pixel_values\n",
        "        pixel_values = pixel_values.squeeze()\n",
        "        label = sample['label']\n",
        "\n",
        "        encoding = dict(pixel_values=pixel_values,\n",
        "                        label=label)\n",
        "        return encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0LupaQx6xJl",
        "outputId": "d96101db-6339-40a5-9f16-5b22f9f7a6de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['image', 'label', 'ground_truth'],\n",
            "    num_rows: 160\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "train_dataset = DocumentDataset(\"nielsr/rvl_cdip_10_examples_per_class_donut\", split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "qgVcnIDW-XF0"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HK1vJ6Eq-qTi",
        "outputId": "61fe8ca5-6194-4533-8850-f3ec8e012a7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['pixel_values', 'label'])\n"
          ]
        }
      ],
      "source": [
        "batch = next(iter(train_dataloader))\n",
        "print(batch.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OkuSc_O_C5g"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5BpMYAdEMFw",
        "outputId": "ed0e7a59-5021-4980-d406-af0d04a34ed6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DonutForImageClassification(\n",
              "  (swin): DonutSwinModel(\n",
              "    (embeddings): DonutSwinEmbeddings(\n",
              "      (patch_embeddings): DonutSwinPatchEmbeddings(\n",
              "        (projection): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
              "      )\n",
              "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): DonutSwinEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0): DonutSwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0-1): 2 x DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=128, out_features=128, bias=True)\n",
              "                  (key): Linear(in_features=128, out_features=128, bias=True)\n",
              "                  (value): Linear(in_features=128, out_features=128, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.1)\n",
              "              (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=128, out_features=512, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=512, out_features=128, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (downsample): DonutSwinPatchMerging(\n",
              "            (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (1): DonutSwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0-1): 2 x DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "                  (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "                  (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.1)\n",
              "              (layernorm_after): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (downsample): DonutSwinPatchMerging(\n",
              "            (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
              "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (2): DonutSwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0-13): 14 x DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.1)\n",
              "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (downsample): DonutSwinPatchMerging(\n",
              "            (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
              "            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (3): DonutSwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0-1): 2 x DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.1)\n",
              "              (layernorm_after): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): AdaptiveAvgPool1d(output_size=1)\n",
              "  )\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (classifier): Linear(in_features=1024, out_features=16, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bdddde1aa8434a06beda81022469b522",
            "a439ab086f94473a86782ecc4f84500d",
            "62a2d5d810fe42e1a0e18e90fe6abddb",
            "6cbacb3e106d49e88c9275e143c21517",
            "8a2b50a2b02e493580a9fb516ded4693",
            "5c736ad6ebb245aabc032213ac38dc10",
            "1ba4bade44d14c2884d857c67d0fcf37",
            "a8c2d26b9f2a4fc4b44459b68d73d9d3",
            "43896d140f55442395d617d0804a0563",
            "f2517c030e264aee81d9101e9fca263e",
            "06b7b57fc95f40a1aeef5a8a2bcea14b",
            "0faeec3574844818a2d4398d68467c7a",
            "5cd8fb03eaff47b184239dbf5ed1690d",
            "82507ddaa76d46dcb3fa44ded5120bf1",
            "a1e28a853f784f16ac08da8eaab2dbad",
            "40743cd6a3d948e8bd761ae6ccaa99af",
            "4b71e5508daa4573bb1e6ac25723387c",
            "3955ba147e254edaa461f0246dc5116c",
            "56abed6f1b034a0bb47c75b996a06981",
            "1877508f96b0467a91cb572d74864d0a",
            "b1b57ebfc0b1440e8c23973e0233607d",
            "8bb465b89cfa40f88ed523f3d7931f54",
            "074996f4174a4e6fb87a9b190282f415",
            "c960856efd154a58bff05f92f5760cc4",
            "20b220bc210e473591241f9dfe7f3d18",
            "077f2476f38447519fe023398b6ceae3",
            "fa175c0afea14d838d009ea640486586",
            "18de19b6db40402d80b905c51b61ced5",
            "9328874772ef4843bde149e54c7dc943",
            "55198131afbf4ed985b29620db696aea",
            "76aafbbc468c4f3aa8924a9abcf46de0",
            "f500630bda554ab89bbd77297fdae8a9",
            "85ddbb7f519c47f987662d16749c8ab0",
            "6f98a8f583474b368ca745d1aaeb0342",
            "ca71048aa0c94362b2e84518fee97a94",
            "211565e940f7432c825881e562217520",
            "ec2ac3b37a8445bd9e396176f969b384",
            "070f060641b7492cbb451bb47d097dcf",
            "88a08488ad28437595d94ab4805d0ff1",
            "8649e9785f80486dab65487be2601e9d",
            "a32e9ccb7b05408dad55ff421345a919",
            "a2b79cd2ad5b4a9d88922b5a68527a4b",
            "bbc564f5ea534729b598450cc2189252",
            "16ff6b53876342968e196fa2bc17e25b",
            "c7ea4097ebca4ea8bba835b795370e3a",
            "ab8e08dea4b14b369a85338fdb7cc53e",
            "f80c1512edba42f9b28127e2e668db98",
            "e44638676f3b4a608748712c29dbd47c",
            "ef56b4f0156f47f8852ef5e5fef799b7",
            "578180772e4b4c82882153d1352316c1",
            "64a300eb2e994301a81e982b431135e6",
            "bf6078110ce442aa93bc6342cc5a4269",
            "f2e1610b429441db87d5f2e5d6ede9d5",
            "055b9e48cb534c5ea29935ed9dcf1099",
            "5a10d4d0baf14b0c800d5fc75dd47af8",
            "55f2f24a32454ec3a6ecf2fdccbe2099",
            "75394891ea254361ab7c3c324f04f7f0",
            "464a6bb836854fc4b46a701d027aaf6b",
            "1f5632dd40e843198bc36fb9b7e633e6",
            "97a2921d7f854bf2b4f6b2c3d04ec7c9",
            "110e9bb7dcd147ddb08014202ff92429",
            "d042692d16074148876d508f84bbc753",
            "1d1ac127bfd24dc0905a5dc08a7612a6",
            "7113117a33f34fd8b8634267b353e589",
            "d5c65734e56549c6b2c646589333c20c",
            "2c7263cfe1634f3fb589942c7dd702dc",
            "07c627109ff94062809cc4408d24e578",
            "7adfb612d29c478cbd809d757bc20aa5",
            "a6dd88cac2a34691b892ed351a88c132",
            "9fdec9918fff4635903a1fe7b944b29c",
            "1be22416e48249a3814fd5cbeb602f1a",
            "aa4b8fbf67fb4976a925698512397a46",
            "645b16882b3c409bbd3f38d85e5fe0e5",
            "852f2297f526475792441fda8a2bc08f",
            "5258644d511e4c7ab51042d66eb3a3cd",
            "f58788edd14840baa1d004c8fd69d2f5",
            "841c7762251046f2b23f3309f5d16022",
            "553a2efb02a74fdb9e758a3294d75702",
            "a95d33d2ca3b4838869760ed17c9c11f",
            "5d2b45167fc24d5f85b8d098d1e4e048",
            "fd28d2e76edd4260bca351cc3c15f362",
            "9369b4e95ac4422dac84a4df7ece32de",
            "44b2d5ef16c04e21822a7e3308130b08",
            "dce8d7c9ccf34e0cbf6f59e8fa4bd889",
            "880d296e19a14e4f91ae879e9a6a3a54",
            "3c9c2dac78d64572868ec5ad86e93900",
            "ecc12d9cabef46df9d0a407e4cbbe3e6",
            "4dee769bd9974cefb8949b4a83b40048",
            "edd494a1ded643e88b7126a22a183e22",
            "082386ee9115443fb52d17baecaee918",
            "fb8bceab626242fc9276eb8dbdcd0429",
            "40594f76ef7546499362d978982e39e5",
            "01c4b6921c734d03931d5fe06f6ee770",
            "ec545598d60647658c1ffac6a9977fd5",
            "54c8376897b34b25ae0b610626860317",
            "c0bf4d169a5245bc80e7b7e7622f3dbf",
            "8a5c91b955824e74b4f643c113f79997",
            "77bf32b2c8fc451aaef8ae4fda25afa1",
            "5f369a075f5a4268ac0d561c0f747e5e",
            "115eb649c5e44b17b607059ff9bb9b5a",
            "74cd8efc6aa042ed8ee98d45788d1ef9",
            "00f76b0012db48d1a2ca4c0cf0039952",
            "40b1a3f895d142e08b988565d5e3d50f",
            "c34553671560439aa7eac8e6b90fdc06",
            "f4431381cba14f2082e197ef57307c5e",
            "f3d831ec6be44b37ba55f209234eb599",
            "8846e560e1744c07abe2b4e60907a00f",
            "dcc52f90840b4af4ae85e084304107c9",
            "5342602978414120bdefddd7f6ea6f42",
            "27d60ef761ea417ebc99391894268eed",
            "ec0f8480256045dc8f6cb9b7c90cf1f4",
            "80b271a571f144269d6f00a2c7653475",
            "b325d3b00df143988b9a21b901b54155",
            "d41d4a684537407eb9a10b85bb0b1693",
            "11bd1118c6434b428d7bc18cbd4f3089",
            "2df5237d36b94d44ad95005767781c56",
            "52291f1100304977bfc9a6c14274e4b0",
            "456db62807554b11a274e670abf9429e",
            "3580148806494e558c9425d005402cc7",
            "86eebc9ef0ce4929b027e293b397efbf",
            "f6fff12f6ed041bc97b78cdd691fb874",
            "bdfc05a73ee8463e8e14587764960a48",
            "7fabc78b38bd4cd6abb0550dce48e9b3",
            "56b4ceee52d44039be50223aabddc3d8",
            "1fce4866257e48f7bb2ab2fb4ad2ac1d",
            "a6a31220b35f4243b0c72a66273368ae",
            "d487246237874c09b4de950bde2d3eb6",
            "189fd6e72ec9418aaf7de7f0b255143f",
            "911a8aa0ab504dfead158b313ff22912",
            "d9b4e72b20964881a262aa0fe0f00e4c",
            "9069fce17f14414e97390288c4b00f1a",
            "ae3c33111060406d9bf0052bc1557766",
            "f99963d07b584708b5a5debf293bbb7e",
            "724dd160f9fb49b7b3b70226b8e60a5c",
            "61c144c2ca1043a6bef497d9392a4590",
            "a9a1215822e441a1a2ae23833abc42ef",
            "8e2f6dc726814937ba4b863bfef76204",
            "9ecc1c4949e2459c952c626aff5faded",
            "836a123ff3c445e88b9f12daedebbb9a",
            "4f18b682705f419c8946c81a0df73c7c",
            "306ac69286be4fc2b9d1898c913939e1",
            "69629933ce3d4643b71980d19d4d81fd",
            "e42c3286f76d422d85c4541d61efc904",
            "79ce25cacd314f62a45852c469f52dab",
            "3e6e733bab25480c95c3d8fab386bb01",
            "034ac49edb1c44468e69d09b7157008d",
            "06da8dcd7a904f40afe6499aee889f28",
            "965a139e56db4e25b900d4d47a4fc0d6",
            "f0e9013953db46899b00155c325eecef",
            "d9691ff7563c477497e578dae020a994",
            "e70fe6bc0fda4b11af52f26a49936474",
            "0f92af38b3b74777ab965fb2fe6226dc",
            "fd3e65acd00c4410a8eceac354d140bd",
            "1dcc5bbec09844a7946fed2f8c637985",
            "46a7d258fe0247e2814a50a95c2bf0b7",
            "a4dd291ed4384bed8842c007f4cfa1cd",
            "3ea8cfb5d5bd4556b578ec08cd3dbdad",
            "82226b01e214423388a084f502a17121",
            "1a4a9c68f22e4993b05e2c2105b336f2",
            "98a2c3e575b64887a26d2aa6648da6d3",
            "ef9d47b4a3fc4d54ab4ffab163eeded8",
            "0703ebb0d3b344df99ee58fbbebe01f3",
            "3bfcda9fa7354d9c8a2483ea04235fc6",
            "52b4e261bc374b3ab169d10bb30e814d",
            "54bad8c1962447a79d310c2883d7501d",
            "eb9a4b7ae85b400399ee2f17105dafc6",
            "ea957daf2d8d463197317d22e5843d9a",
            "6a7e87a85e154439ba908754e7a7aa5e",
            "8db66a13ff78444c824c0a8c8aa15fa6",
            "9ca240155bc44c469a961a4ebf212594",
            "4397ea896a444571afe3f72368366afd",
            "43dd7704d3be494aa4db76381dae3638",
            "e17646ed9dbf4e1e9ad3fa2eccf49f03",
            "74124b098c8b4b2e8d643e584e4db59f",
            "a64a2ae1d85a477bb494d7286abee71a",
            "ab809b2a627840539975db7c1e76ea37",
            "aa3a5e855ee44507b8ecea5cadfed510",
            "eef38fa5561a4bb2a181409a4ab43b3e",
            "780f36058e624c29a0c2a9cfd940517f",
            "480153dcfde64f028ca414aeb4af0b3f",
            "cb61b2f8a9e4489a96c8baf583b25ed2",
            "710d1b6d20044986b36fa684b816351d",
            "2138b4fbb1294d9caa50ecc9025e3dfa",
            "b5e065d70611417f87618db49583bc7a",
            "b00a148d0260400c83d4327a775bc663",
            "9405c5d66172477ca52c2f67d4763226",
            "562190dec2dc4cc19787c3155654e5b4",
            "d49ecee5209140c186478910f57e0c3d",
            "72876e1b97ae4c0c813473106b58635a",
            "e1b24cd10e504d1da5d85c50ee8039f0",
            "b43e037e3d904dac9d9b3feffd529186",
            "88286acf67a241f3a1a4a5042f9ff6f0",
            "38c268eaebbd4aa1a8d17b380c9227f7",
            "3f4abda36f184f8e991cde1e4e18bbcc",
            "3a69a8e396e642a590f63fe7e2559fb1",
            "e45bdf0b163741cabe584f9465c10127",
            "ef5b27fd9ee4441182da88255f35b0d4",
            "45c5ee5b288f45c4b2ca6c51a02fbc63",
            "4b6ba26142cc4e5985a1e6921ca47786",
            "664b994f2e9e4639997e194fb96b9b7e",
            "c5d944613aca4a0daaadbe34f9e36029",
            "e79aeb533aa5402d97f1b1f75257a8b1",
            "c7d092c7f44e414cbefb89b17cd3237b",
            "ffcad802ea404d57b06b43bac9dece61",
            "d18fdd4ea55d4b7fae83e8c007154bd6",
            "41c5c1c0fcde41209c7da3ed49448707",
            "7f86eb8cabad45fd92ebb3932ea49cfe",
            "bd085e7013874fc3a1f3def7826fbd1f",
            "9ef90c2480d342b084dd70c4d9ff227b",
            "324076ca5fc746b5a241cf2c0f67c88d",
            "8a7b8edd337a41ceb37885dbdb87f37c",
            "1e3c6530b3e640ab96b73dd72936363a",
            "62b8caddfcb04f539f56f0a14d467df4",
            "6a3546ca17f447afb840725315119fb2",
            "2f361ff09318420b9da101f5213da52f",
            "4c5e51837db244fdacc0815f584d2ddc",
            "f390927711224639a7b04bb0ca4c38c4",
            "4cbb37cad4334b71aff718ed3f54d6e5",
            "b9dce1cae1554d568aff6e67027b946f",
            "8911af835e39474fbfb4745187f06fd5"
          ]
        },
        "id": "ba4uT5u_-swt",
        "outputId": "c0fb71b9-751c-46c3-ff98-30d063e02c53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdddde1aa8434a06beda81022469b522",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 3.70231556892395\n",
            "Loss: 3.024982452392578\n",
            "Epoch: 2\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0faeec3574844818a2d4398d68467c7a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.541522264480591\n",
            "Loss: 2.860440969467163\n",
            "Epoch: 3\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "074996f4174a4e6fb87a9b190282f415",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.630465269088745\n",
            "Loss: 2.1937198638916016\n",
            "Epoch: 4\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f98a8f583474b368ca745d1aaeb0342",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.7742600440979004\n",
            "Loss: 0.9532672166824341\n",
            "Epoch: 5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7ea4097ebca4ea8bba835b795370e3a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.4238550662994385\n",
            "Loss: 4.296530246734619\n",
            "Model saved at model_epoch_5.pth\n",
            "Epoch: 6\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55f2f24a32454ec3a6ecf2fdccbe2099",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 3.739987373352051\n",
            "Loss: 0.6943356990814209\n",
            "Epoch: 7\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07c627109ff94062809cc4408d24e578",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.7329750061035156\n",
            "Loss: 1.1023378372192383\n",
            "Epoch: 8\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "553a2efb02a74fdb9e758a3294d75702",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.6882001161575317\n",
            "Loss: 0.9208144545555115\n",
            "Epoch: 9\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edd494a1ded643e88b7126a22a183e22",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.4631640911102295\n",
            "Loss: 0.4820936322212219\n",
            "Epoch: 10\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "115eb649c5e44b17b607059ff9bb9b5a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.005439955275505781\n",
            "Loss: 1.6626732349395752\n",
            "Model saved at model_epoch_10.pth\n",
            "Epoch: 11\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec0f8480256045dc8f6cb9b7c90cf1f4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.2733348309993744\n",
            "Loss: 1.2818022966384888\n",
            "Epoch: 12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdfc05a73ee8463e8e14587764960a48",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.03281886503100395\n",
            "Loss: 0.05230311304330826\n",
            "Epoch: 13\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f99963d07b584708b5a5debf293bbb7e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.001836162875406444\n",
            "Loss: 0.2656080424785614\n",
            "Epoch: 14\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "79ce25cacd314f62a45852c469f52dab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.12347044050693512\n",
            "Loss: 3.2924883365631104\n",
            "Epoch: 15\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46a7d258fe0247e2814a50a95c2bf0b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.09693533182144165\n",
            "Loss: 2.4978222846984863\n",
            "Model saved at model_epoch_15.pth\n",
            "Epoch: 16\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb9a4b7ae85b400399ee2f17105dafc6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.12904950976371765\n",
            "Loss: 0.14737243950366974\n",
            "Epoch: 17\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa3a5e855ee44507b8ecea5cadfed510",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.05589354410767555\n",
            "Loss: 0.07741816341876984\n",
            "Epoch: 18\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d49ecee5209140c186478910f57e0c3d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.6614376306533813\n",
            "Loss: 0.007626701612025499\n",
            "Epoch: 19\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b6ba26142cc4e5985a1e6921ca47786",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0004589696181938052\n",
            "Loss: 1.743046522140503\n",
            "Epoch: 20\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "324076ca5fc746b5a241cf2c0f67c88d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.1126399114727974\n",
            "Loss: 2.5018186569213867\n",
            "Model saved at model_epoch_20.pth\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "optimizer = torch.optim.AdamW(params=model.parameters(), lr=1e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(20):\n",
        "    print(\"Epoch:\", epoch+1)\n",
        "    model.train()\n",
        "    for i, batch in enumerate(tqdm(train_dataloader)):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        pixel_values = batch[\"pixel_values\"]\n",
        "        labels = batch[\"label\"]\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(pixel_values=pixel_values)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(\"Loss:\", loss.item())\n",
        "\n",
        "    if epoch + 1 in {5, 10, 15, 20}:\n",
        "        checkpoint_path = f\"model_epoch_{epoch+1}.pth\"\n",
        "        torch.save(model.state_dict(), checkpoint_path)\n",
        "        print(f\"Model saved at {checkpoint_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtLBVAmVcupt"
      },
      "source": [
        "# Evaluate and Benchmark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMeM3_YPc04Y"
      },
      "source": [
        " Run the cell to compute average inference time and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwdosMoENgeY",
        "outputId": "0a49eb6d-3866-4874-e932-ebace2f4cc02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 51.875%\n",
            "Predicted 83 correctly out of 160!\n",
            "Average Inference time: 0.029348 seconds\n"
          ]
        }
      ],
      "source": [
        "# Evaluation loop\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "model.load_state_dict(torch.load('/content/model_epoch_20.pth'))\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "dataset = load_dataset(\"nielsr/rvl_cdip_10_examples_per_class_donut\", split=\"test\")\n",
        "inference_time = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for sample in dataset:\n",
        "        pixel_values = processor(sample[\"image\"].convert(\"RGB\"), return_tensors=\"pt\").pixel_values\n",
        "        pixel_values = pixel_values.to(device)\n",
        "        labels = sample[\"label\"]\n",
        "        start_time = time.time()\n",
        "        outputs = model(pixel_values)\n",
        "        end_time = time.time()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += 1\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        inference_time.append(end_time - start_time)\n",
        "\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy: {accuracy}%')\n",
        "print(f'Predicted {correct} correctly out of {total}!')\n",
        "print(f\"Average Inference time: {np.mean(inference_time):.6f} seconds\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
